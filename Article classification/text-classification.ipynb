{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8c58d7b0-c160-4fbd-bb53-757bb5aabc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acee8cd-09e5-41b4-a442-9f9970cdee16",
   "metadata": {},
   "source": [
    "### A) Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db373b-f1e3-4fd9-85e7-8b53638d8e2f",
   "metadata": {},
   "source": [
    "#### Load unstructured unlabelled sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e4c1d0c9-bd72-4d3a-a7ac-073453cb106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhole-genome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available.\\nFor each organism, the complete set of membrane transport systems was identified with predicted functions, and classified into protein families based on the transporter classification system.\\nOrganisms with larger genome sizes generally possessed a relatively greater number of transport systems.\\nIn prokaryotes and unicellular eukaryotes, the significant factor in the increase in transporter content with genome size was a greater diversity of transporter types.\\nIn contrast, in multicellular eukaryotes, greater number of paralogs in specific transporter families was the more important factor in the increase in transporter content with genome size.\\nBoth eukaryotic and prokaryotic intracellular pathogens and endosymbionts exhibited markedly limited transport capabilities.\\nHierarchical clustering of phylogenetic profiles of transporter families, derived from the presence or absence of a certain transporter family, showed that clustering patterns of organisms were correlated to both their evolutionary history and their overall physiology and lifestyles.\\n\\n\\nMembrane transport systems play essential roles in cellular metabolism and activities.\\nTransporters function in the acquisition of organic nutrients, maintenance of ion homeostasis, extrusion of toxic and waste compounds, environmental sensing and cell communication, and other important cellular functions CITATION.\\nVarious transport systems differ in their putative membrane topology, energy coupling mechanisms, and substrate specificities CITATION.\\nAmong the prevailing energy sources are adenosine triphosphate, phosphoenolpyruvate, and chemiosmotic energy in the form of sodium ion or proton electrochemical gradients.\\nThe transporter classification system represents a systematic approach to classify transport systems according to their mode of transport, energy coupling mechanism, molecular phylogeny, and substrate specificity CITATION CITATION.\\nTransport mode and energy coupling mechanism serve as the primary basis for classification because of their relatively stable characteristics.\\nThere are four major classes of solute transporters in the transporter classification system: channels, primary transporters, secondary transporters, and group translocators.\\nTransporters of unknown mechanism or function are included as a distinct class.\\nChannels are energy-independent transporters that transport water, specific types of ions, or hydrophilic small molecules down a concentration or electrical gradient; they have higher rates of transport and lower stereospecificity than the other transporter classes.\\nPrimary active transporters couple the transport process to a primary source of energy.\\nSecondary transporters utilize an ion or solute electrochemical gradient, e.g., proton/sodium motive force, to drive the transport process.\\nE. coli LacY lactose permease CITATION, CITATION is probably one of the best characterized secondary transporters CITATION.\\nGroup translocators modify their substrates during the transport process.\\nFor example, E. coli MtlA mannitol PTS transporter phosphorylates exogenous mannitol using phosphoenolpyruvate as the phosphoryl donor and energy source and releases the phosphate ester, mannitol-1-P, into the cell cytoplasm CITATION, CITATION.\\nEach transporter class is further classified into individual families and subfamilies according to their function, phylogeny, and/or substrate specificity CITATION .\\nSince the advent of genomic sequencing technologies, the complete sequences of over 200 prokaryotic and eukaryotic genomes have been published to date, representing a wide range of species from archaea to human.\\nThere are also more than 1,100 additional genome sequencing projects currently underway around the world CITATION, CITATION.\\nConvenient and effective computational methods are required to handle and analyze the immense amount of data generated by the whole-genome sequencing projects.\\nAn in-depth look at transport proteins is vital to the understanding of the metabolic capability of sequenced organisms.\\nHowever, it is often problematic to annotate these transport proteins by current primary annotation methods because of the occurrence of large and complex transporter gene families, such as the ATP-binding cassette superfamily CITATION, CITATION and the major facilitator superfamily CITATION, CITATION, and the presence of multiple transporter gene paralogs in many organisms.\\nWe have been working on a systematic genome-wide analysis of cellular membrane transport systems.\\nPreviously, we reported a comprehensive analysis of the transport systems in 18 prokaryotic organisms CITATION, CITATION and in yeast CITATION.\\nHere we expand our analyses to 141 species and compare the fundamental differences in membrane transport systems in prokaryotes and eukaryotes.\\nPhylogenetic profiling of transporter families and predicted substrates was utilized to investigate the relevance of transport capabilities to the overall physiology of prokaryotes and eukaryotes.\\n\\n\\nA central problem in the bioinformatics of gene regulation is to find the binding sites for regulatory proteins.\\nOne of the most promising approaches toward identifying these short and fuzzy sequence patterns is the comparative analysis of orthologous intergenic regions of related species.\\nThis analysis is complicated by various factors.\\nFirst, one needs to take the phylogenetic relationship between the species into account in order to distinguish conservation that is due to the occurrence of functional sites from spurious conservation that is due to evolutionary proximity.\\nSecond, one has to deal with the complexities of multiple alignments of orthologous intergenic regions, and one has to consider the possibility that functional sites may occur outside of conserved segments.\\nHere we present a new motif sampling algorithm, PhyloGibbs, that runs on arbitrary collections of multiple local sequence alignments of orthologous sequences.\\nThe algorithm searches over all ways in which an arbitrary number of binding sites for an arbitrary number of transcription factors can be assigned to the multiple sequence alignments.\\nThese binding site configurations are scored by a Bayesian probabilistic model that treats aligned sequences by a model for the evolution of binding sites and background intergenic DNA.\\nThis model takes the phylogenetic relationship between the species in the alignment explicitly into account.\\nThe algorithm uses simulated annealing and Monte Carlo Markov-chain sampling to rigorously assign posterior probabilities to all the binding sites that it reports.\\nIn tests on synthetic data and real data from five Saccharomyces species our algorithm performs significantly better than four other motif-finding algorithms, including algorithms that also take phylogeny into account.\\nOur results also show that, in contrast to the other algorithms, PhyloGibbs can make realistic estimates of the reliability of its predictions.\\nOur tests suggest that, running on the five-species multiple alignment of a single gene's upstream region, PhyloGibbs on average recovers over 50 percent of all binding sites in S. cerevisiae at a specificity of about 50 percent, and 33 percent of all binding sites at a specificity of about 85 percent.\\nWe also tested PhyloGibbs on collections of multiple alignments of intergenic regions that were recently annotated, based on ChIP-on-chip data, to contain binding sites for the same TF.\\nWe compared PhyloGibbs's results with the previous analysis of these data using six other motif-finding algorithms.\\nFor 16 of 21 TFs for which all other motif-finding methods failed to find a significant motif, PhyloGibbs did recover a motif that matches the literature consensus.\\nIn 11 cases where there was disagreement in the results we compiled lists of known target genes from the literature, and found that running PhyloGibbs on their regulatory regions yielded a binding motif matching the literature consensus in all but one of the cases.\\nInterestingly, these literature gene lists had little overlap with the targets annotated based on the ChIP-on-chip data.\\nThe PhyloGibbs code can be downloaded from LINK or LINK.\\nThe full set of predicted sites from our tests on yeast are available at LINK.\\n\\n\\nTranscription factors are proteins that bind in a sequence-specific manner to short DNA segments, most commonly in intergenic DNA upstream of a gene, to activate or suppress gene transcription.\\nTheir DNA-binding domains recognize collections of short related DNA sequences.\\nOne generally finds that, although there is no unique combination of bases that is shared by all binding sites, and although different bases can occur at each position, there are clear biases in the distribution of bases that occur at each position of the binding sites.\\nA common mathematical representation of a motif that takes this variability into account is a so-called weight matrix CITATION, CITATION w, whose components w i give the probabilities of finding base A, C, G, T at position i of a binding site.\\nThe main assumption underlying this mathematical representation is that the bases occurring at different positions of the binding site are probabilistically independent.\\nThis in turn follows, under some conditions CITATION, from the assumption that the binding energy of the protein to the DNA is a sum of pairwise contact energies between the individual nucleotides and the protein.\\nThere are several algorithms that are based on the WM representation that detect, ab initio, binding sites for a common TF in a collection of DNA sequences CITATION CITATION.\\nThese algorithms broadly fall into two classes.\\nOne class, of which MEME CITATION is the typical representative, searches the space of all WMs for the WM that can best explain the observed sequences.\\nThe class of Gibbs sampling algorithms, of which the Gibbs motif sampler CITATION, CITATION is the typical representative, instead samples the space of all multiple alignments of small sequence segments in search of the one that is most likely to consist of samples from a common WM.\\nA crucial factor for the success of ab initio methods is the ratio of the number of binding sites to the total amount of DNA in the collection of sequences.\\nThat is, the larger the number of binding sites in the set, and the smaller the total amount of DNA, the more likely it is that ab initio methods can discover the binding sites among the other DNA sequences.\\nIn order to ensure a reasonable chance of success one thus needs to provide these methods with collections of sequences that are highly enriched with binding sites for a common TF.\\nOne possibility is to use sets of upstream regions from genes that appear co-regulated in microarray experiments or that were bound by a common TF in ChIP-on-chip experiments.\\nAnother possibility is to use upstream regions of orthologous genes from related organisms.\\nHere the assumption is that the regulation of the ancestor gene, and thus its binding sites, has been conserved in the orthologs that descend from it.\\nThis latter approach is in general complicated by a number of factors.\\nWhen searching for regulatory sites in sequences that are not phylogenetically related, such as upstream regions of different genes from the same organism, one may simply look for short sequence motifs that are overrepresented among the input sequences.\\nIf the set of species from which the orthologous sequences derive are sufficiently diverged, one may simply choose to ignore the phylogenetic relationship between the sequences and treat the orthologous sequences in the same way as sequences that are not phylogenetically related.\\nThis was, for instance, the approach taken by McCue et al. CITATION, CITATION, where the Gibbs motif sampler algorithm CITATION, CITATION was used on upstream regions of proteo- bacteria.\\nHowever, this approach is not applicable to datasets containing more closely related species, where some of the sequences will exhibit significant amounts of similarity simply because of their evolutionary proximity.\\nMoreover, the amount of similarity will depend on the phylogenetic distance between the species, and it is clear that finding conserved sequence motifs between orthologous sequences from closely related species is much less indicative of function than finding sequence motifs that are conserved between distant species.\\nOne will in general thus have to distinguish conservation due to functional constraints from conservation due to evolutionary proximity, and to do this correctly, the phylogenetic relationship between the sequences has to be taken into account.\\nA second challenge in using orthologous intergenic sequences from multiple species is the nontrivial structure of their multiple alignments.\\nOne typically finds a very heterogeneous pattern of conservation: well-conserved blocks of different sizes and covering different subsets of the species are interspersed with sequence segments that show little similarity with the sequences of the other species.\\nThe technique of phylogenetic footprinting, restricts attention to only those sequence segments in the genome of interest that show significant conservation with the other species.\\nThe conserved regions for multiple genes are then searched for common motifs by a variety of techniques.\\nIt is unclear, however, to what extent regulatory sites are restricted to such conserved segments.\\nFor instance, several studies of Drosophila and yeast CITATION CITATION have shown that there is no strong correlation between where experimentally annotated binding sites occur and whether that region is conserved.\\nThus, at least for yeast and flies, considerable information is lost by focusing on the conserved regions only.\\nWe thus decided to retain the entire patchwork pattern of conserved sequence blocks and unaligned segments.\\nOur strategy is implemented by a Gibbs sampling approach, and a preliminary account of the algorithm was presented in CITATION.\\nThe algorithm operates on arbitrary collections of both phylogenetically related sequences, such as orthologous intergenic regions, and sequences that are not phylogenetically related, such as upstream regions of different genes from the same organism.\\nThe phylogenetically related groups of sequences in the input are pre-aligned into local multiple alignments where clearly similar sequence segments are aligned into blocks and sequence segments of no or marginal similarity are left unaligned CITATION.\\nAlthough the algorithm can also take global multiple alignments as input, we believe that these often force phylogenetically unrelated segments into aligned blocks.\\nThis may adversely affect the performance of the algorithm.\\nWe score putative sites within blocks of aligned sequences with an evolutionary model that takes the phylogenetic relationships of the species into account, while putative sites in unaligned segments are treated as independent occurrences.\\nThis Bayesian model defines a probability distribution over arbitrary placements of putative binding sites for multiple motifs, and we sample it with a Monte Carlo Markov chain.\\nWe first use simulated annealing to search for the globally optimal configuration of binding sites.\\nThe motifs in this configuration are then tracked in a further sampling run to estimate realistic posterior probabilities for all the binding sites that the algorithm reports.\\nRecently a number of other algorithms have been developed that search for regulatory motifs in groups of phylogenetically related sequences.\\nProbably the first algorithm that was proposed is a generalization of the Consensus algorithm CITATION called PhyloCon CITATION.\\nPhyloCon operates on sets of co-regulated genes and their orthologs.\\nIt is a greedy algorithm that first finds ungapped alignments of similar sequence segments in sets of orthologous sequences, and then combines these alignments from different upstream regions into larger alignments.\\nThis algorithm does not take any phylogenetic information into account, i.e., closely related sequences are treated the same as distantly related sequences.\\nOther drawbacks of this algorithm are that it assumes that each motif will have exactly one site in each of the intergenic regions and that it assumes that this site is conserved in all orthologs.\\nMore closely related to PhyloGibbs's approach are two recent algorithms CITATION, CITATION that generalize MEME CITATION to take the phylogenetic relationships between species into account.\\nThe main difference between EMnEM and PhyME is that PhyME uses the same evolutionary model for the evolution of binding sites as PhyloGibbs, which takes into account that binding sites evolve under constraints set by a WM, whereas EMnEM simply assumes an overall slower rate of evolution in binding sites than in background sequences.\\nAnother difference is that PhyME, like PhyloGibbs, treats the multiple alignment more flexibly than EMnEM, which demands a global multiple alignment.\\nThe main difference between PhyloGibbs and these algorithms is of course that PhyloGibbs takes a motif sampling approach, which allows us to search for multiple motifs in parallel, whereas PhyME and EMnEM use expectation maximization to search for one WM at a time.\\nIn the following sections, we first describe our Bayesian model that assigns a posterior probability to each configuration of binding sites for multiple motifs assigned to the input sequences.\\nWe start by describing the model for phylogenetically unrelated sequences, which is essentially equivalent to the model used in the Gibbs motif sampler CITATION, CITATION, and then describe how this model is extended to datasets that contain phylogenetically related sequences.\\nAfter that we describe the move set with which we search the state space of all possible configurations, and the annealing and tracking strategy that we use to identify the significant groups of sites.\\nWe then present examples of the performance of ours and other algorithms on both synthetic and real data.\\nThe synthetic datasets consist of mixtures of WM samples and random sequences, which is in accordance with assumptions that all algorithms make.\\nThis allows us to compare the performance of the algorithms in an idealized situation that does not contain the complexities of real data.\\nThese tests also show to what extent binding sites can be recovered for this idealized data as a function of the quality of the WMs, the number of sites available, and the number of species available and their phylogenetic distances.\\nFor our tests on real data we use 200 upstream regions from Saccharomyces cerevisiae that have known binding sites from the collection CITATION, and compare the ability of the different algorithms to recover these sites when running on multiple alignments of the orthologs of these upstream regions from recently sequenced Saccharomyces genomes CITATION, CITATION.\\nFinally, we run PhyloGibbs on collections of upstream region alignments that were annotated in CITATION to contain binding sites for a common TF based on data from ChIP-on-chip experiments, and we extensively compare PhyloGibbs' results with the annotations in CITATION and with the literature.\\n\""
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [i for i in glob.glob(os.path.expanduser(\"./unlabeled_dataset/*.txt\"))]\n",
    "\n",
    "# Initialize an empty string\n",
    "rawUnlabeledData = \"\"\n",
    "\n",
    "# Loop through the files and read each into the string\n",
    "for file in filenames:\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "        # Remove unecessary titles\n",
    "        content = content.replace('### abstract ###', '\\n').replace('### introduction ###', '\\n')\n",
    "    rawUnlabeledData += content\n",
    "\n",
    "rawUnlabeledData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e255b-3692-4f2e-922f-0fc50a867652",
   "metadata": {},
   "source": [
    "#### Load unstructured labelled sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3963c39a-0330-48a5-8289-f87ec06bca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMISC\\talthough the internet as level topology has been extensively studied over the past few years  little is known about the details of the as taxonomy\\nMISC\\tan as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastly different network characteristics  external connectivity patterns  network growth tendencies  and other properties that we can hardly neglect while working on veracious internet representations in simulation environments\\nAIMX\\tin this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy\\nOWNX\\twe successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent \\nOWNX\\twe release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   the set of as attributes we used to classify ases\\nOWNX\\twe believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the internet\\n\\n\\nMISC\\tthe rapid expansion of the internet in the last two decades has produced a large scale system of thousands of diverse  independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments\\nMISC\\tfrom  NUMBER  to  NUMBER  the number of globally routable as identifiers has increased from less than  NUMBER   NUMBER  to more than  NUMBER   NUMBER   exerting significant pressure on interdomain routing as well as other functional and structural parts of the internet\\nMISC\\tthis impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the internet infrastructure\\nMISC\\tin particular  the as level topology is an intermix of networks owned and operated by many different organizations  e g   backbone providers  regional providers  access providers  universities and private companies\\nMISC\\tstatistical information that faithfully characterizes different as types is on the critical path toward understanding the structure of the internet  as well as for modeling its topology and growth\\nMISC\\tin topology modeling  knowledge of as types is mandatory for augmenting synthetically constructed or measured as topologies with realistic intra as and inter as router level topologies\\nMISC\\tfor example  we expect the network of a dual homed university to be drastically different from that of a dual homed small company\\nMISC\\tthe university will likely contain dozens of internal routers  thousands of hosts  and many other network elements  switches  servers  firewalls \\nMISC\\ton the other hand  the small company will most probably have a single router and a simple network topology\\nMISC\\tsince there is such a diversity among different network types  we cannot accurately augment the as level topology with appropriate router level topologies if we cannot MISC\\tcharacterize the composing ases\\nMISC\\tmoreover  annotating the ases in the as topology with their types is a prerequisite for modeling the evolution of the internet  since different types of ases exhibit different growth patterns\\nMISC\\tfor example  internet service providers  isp  grow by attracting new customers and by engaging in business agreements with other isps\\nMISC\\ton the other hand  small companies that connect to the internet through one or few isps do not grow significantly over time\\nMISC\\tthus  categorizing different types of ases in the internet is necessary to identify network evolution patterns and develop accurate evolution models\\nMISC\\tan as taxonomy is also necessary for mapping ip addresses to different types of users\\nMISC\\tfor example  in traffic analysis studies its often required to distinguish between packets that come from home and business users\\nMISC\\tgiven an as taxonomy  its possible to realize this goal by checking the type of as that originates the prefix in which an ip address lies\\nAIMX\\tin this work  we introduce a radically new approach based on machine learning to construct a representative as taxonomy\\nOWNX\\twe develop an algorithm to classify ases based on empirically observed differences between as characteristics\\nOWNX\\twe use a large set of data from the internet routing registries  irr   CITATION  and from routeviews  CITATION  to identify intrinsic differences between ases of different types\\nAIMX\\tthen  we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ases into six representative classes that reflect ases with different network properties and infrastructures\\nOWNX\\twe derive macroscopic statistics on the different types of ases in the internet and validate our results using a sample of  NUMBER  manually identified as types\\nOWNX\\tour validation demonstrates that our classification algorithm achieves high accuracy   NUMBER   NUMBER  percent  of the examined classifications were correct\\nOWNX\\tfinally  we make our results and our classifier publicly available to promote further research and understanding of the internet s structure and evolution\\nOWNX\\tin section  we start with a brief discussion of related work\\nOWNX\\tsection  describes the data we used  and in section  we specify the set of as classes we use in our experiments\\nOWNX\\tsection  introduces our classification approach and results\\nOWNX\\twe validate them in section  and conclude in section \\n\\n\\nMISC\\talthough the internet as level topology has been extensively studied over the past few years  little is known about the details of the as taxonomy\\nMISC\\tan as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastly different network characteristics  external connectivity patterns  network growth tendencies  and other properties that we can hardly neglect while working on veracious internet representations in simulation environments\\nAIMX\\tin this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy\\nOWNX\\twe successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent \\nOWNX\\twe release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   the set of as attributes we used to classify ases\\nOWNX\\twe believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the internet\\n\\n\\nMISC\\tthe rapid expansion of the internet in the last two decades has produced a large scale system of thousands of diverse  independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments\\nMISC\\tfrom  NUMBER  to  NUMBER  the number of globally routable as identifiers has increased from less than  NUMBER   NUMBER  to more than  NUMBER   NUMBER   exerting significant pressure on interdomain routing as well as other functional and structural parts of the internet\\nMISC\\tthis impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the internet infrastructure\\nMISC\\tin particular  the as level topology is an intermix of networks owned and operated by many different organizations  e g   backbone providers  regional providers  access providers  universities and private companies\\nMISC\\tstatistical information that faithfully characterizes different as types is on the critical path toward understanding the structure of the internet  as well as for modeling its topology and growth\\nMISC\\tin topology modeling  knowledge of as types is mandatory for augmenting synthetically constructed or measured as topologies with realistic intra as and inter as router level topologies\\nMISC\\tfor example  we expect the network of a dual homed university to be drastically different from that of a dual homed small company\\nMISC\\tthe university will likely contain dozens of internal routers  thousands of hosts  and many other network elements  switches  servers  firewalls \\nMISC\\ton the other hand  the small company will most probably have a single router and a simple network topology\\nMISC\\tsince there is such a diversity among different network types  we cannot accurately augment the as level topology with appropriate router level topologies if we cannot characterize the composing ases\\nMISC\\tmoreover  annotating the ases in the as topology with their types is a prerequisite for modeling the evolution of the internet  since different types of ases exhibit different growth patterns\\nMISC\\tfor example  internet service providers  isp  grow by attracting new customers and by engaging in business agreements with other isps\\nMISC\\ton the other hand  small companies that connect to the internet through one or few isps do not grow significantly over time\\nMISC\\tthus  categorizing different types of ases in the internet is necessary to identify network evolution patterns and develop accurate evolution models\\nMISC\\tan as taxonomy is also necessary for mapping ip addresses to different types of users\\nMISC\\tfor example  in traffic analysis studies its often required to distinguish between packets that come from home and business users\\nMISC\\tgiven an as taxonomy  its possible to realize this goal by checking the type of as that originates the prefix in which an ip address lies\\nAIMX\\tin this work  we introduce a radically new approach based on machine learning to construct a representative as taxonomy\\nAIMX\\twe develop an algorithm to classify ases based on empirically observed differences between as characteristics\\nOWNX\\twe use a large set of data from the internet routing registries  irr   CITATION  and from routeviews  CITATION  to identify intrinsic differences between ases of different types\\nOWNX\\tthen  we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ases into six representative classes that reflect ases with different network properties and infrastructures\\nOWNX\\twe derive macroscopic statistics on the different types of ases in the internet and validate our results using a sample of  NUMBER  manually identified as types\\nOWNX\\tour validation demonstrates that our classification algorithm achieves high accuracy   NUMBER   NUMBER  percent  of the examined classifications were correct\\nOWNX\\tfinally  we make our results and our classifier publicly available to promote further research and understanding of the internet s structure and evolution\\nBASE\\tin section  we start with a brief discussion of related work\\nOWNX\\tsection  describes the data we used  and in section  we specify the set of as classes we use in our experiments\\nOWNX\\tsection  introduces our classification approach and results\\nOWNX\\twe validate them in section  and conclude in section \\n\\n\\nMISC Although the Internet AS-level topology has been extensively studied over the past few years, little is known about the details of the AS taxonomy\\nMISC An AS \"node\" can represent a wide variety of organizations, e g , large ISP, or small private business, university, with vastly different network characteristics, external connectivity patterns, network growth tendencies, and other properties that we can hardly neglect while working on veracious Internet representations in simulation environments\\nAIMX In this paper, we introduce a radically new approach based on machine learning techniques to map all the ASes in the Internet into a natural AS taxonomy\\nOWNX We successfully classify ~95.3\\\\% of ASes with expected accuracy of ~78.1\\\\%\\nOWNX We release to the community the AS-level topology dataset augmented with: 1) the AS taxonomy information and 2) the set of AS attributes we used to classify ASes\\nOWNX We believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the Internet\\n\\n\\nMISC The rapid expansion of the Internet in the last two decades has produced a large-scale system of thousands of diverse, independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments\\nMISC From 1997 to 2005 the number of globally routable AS identifiers has increased from less than 2,000 to more than 20,000, exerting significant pressure on interdomain routing as well as other functional and structural parts of the Internet\\nMISC This impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the Internet infrastructure\\nMISC In particular, the AS-level topology is an intermix of networks owned and operated by many different organizations, e g , backbone providers, regional providers, access providers, universities and private companies\\nMISC Statistical information that faithfully characterizes different AS types is on the critical path toward understanding the structure of the Internet, as well as for modeling its topology and growth\\nMISC In topology modeling, knowledge of AS types is mandatory for augmenting synthetically constructed or measured AS topologies with realistic intra-AS and inter-AS router-level topologies\\nMISC For example, we expect the network of a dual-homed university to be drastically different from that of a dual-homed small company\\nMISC The university will likely contain dozens of internal routers, thousands of hosts, and many other network elements (switches, servers, firewalls)\\nMISC On the other hand, the small company will most probably have a single router and a simple network topology\\nMISC Since there is such a diversity among different network types, we cannot accurately augment the AS-level topology with appropriate router-level topologies if we cannot characterize the composing ASes\\nMISC Moreover, annotating the ASes in the AS topology with their types is a prerequisite for modeling the evolution of the Internet, since different types of ASes exhibit different growth patterns\\nMISC For example, Internet Service Providers (ISP) grow by attracting new customers and by engaging in business agreements with other ISPs\\nMISC On the other hand, small companies that connect to the Internet through one or few ISPs do not grow significantly over time\\nMISC Thus, categorizing different types of ASes in the Internet is necessary to identify network evolution patterns and develop accurate evolution models\\nMISC An AS taxonomy is also necessary for mapping IP addresses to different types of users\\nMISC For example, in traffic analysis studies its often required to distinguish between packets that come from home and business users\\nMISC Given an AS taxonomy, its possible to realize this goal by checking the type of AS that originates the prefix in which an IP address lies\\nAIMX In this work, we introduce a radically new approach based on machine learning to construct a representative AS taxonomy\\nOWNX We develop an algorithm to classify ASes based on empirically observed differences between AS characteristics\\nBASE We use a large set of data from the Internet Routing Registries~(IRR)~ CITATION  and from RouteViews~ CITATION  to identify intrinsic differences between ASes of different types\\nOWNX Then, we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ASes into six representative classes that reflect ASes with different network properties and infrastructures\\nOWNX We derive macroscopic statistics on the different types of ASes in the Internet and validate our results using a sample of~1200 manually identified AS types\\nOWNX Our validation demonstrates that our classification algorithm achieves high accuracy:~78 1\\\\% of the examined classifications were correct\\nOWNX Finally, we make our results and our classifier publicly available to promote further research and understanding of the Internet\\'s structure and evolution\\nOWNX In Section~ we start with a brief discussion of related work\\nOWNX Section~ describes the data we used, and in Section~ we specify the set of AS classes we use in our experiments\\nOWNX Section~ introduces our classification approach and results\\nOWNX We validate them in Section~ and conclude in Section~\\n\\n\\nAIMX\\tin this paper we derive the equations for loop corrected belief propagation on a continuous variable gaussian model\\nOWNX\\tusing the exactness of the averages for belief propagation for gaussian models  a  different way of obtaining the covariances is found   based on belief propagation on cavity graphs\\nOWNX\\twe discuss the relation of this  loop correction algorithm to expectation propagation  algorithms for the case in which the model is no longer  gaussian  but slightly perturbed by nonlinear terms\\n\\n\\nMISC\\tmessage passing techniques in graphical models allow for the computation of  approximate   marginal probabilities in a time interval scaling polynomially in the  model size\\nMISC\\ttheir discovery has consequently revolutionized several  fields of applications in the past years  of which error correcting codes and vision are probably the most prominent examples\\nMISC\\tin many cases  the corresponding graphs are loopy  implying either that the error resulting from the application of loopy belief propagation  bp  is negligible for the particular model  or it  can be tolerated for the particular purpose bp serves\\nMISC\\tin other cases  more sophisticated refinements of bp are necessary  taking into account  part of  the loop errors\\nMISC\\tfinding the optimal treatment of these   loop errors    motivates an active field of research  in which  different solutions applying to different model classes are developed\\nMISC\\tfor models involving many short loops   like on regular lattices  cvm type approaches work well  CITATION   or tree ep approaches  CITATION\\nMISC\\tthe latter may also be  applied to correct for an incidental large loop\\nMISC\\tunifying frameworks like the region graphs of  CITATION   lead to general strategies for selecting the basic clusters underlying such approaches for general model classes\\nMISC\\ta recent analysis has shown that the local update equations of bp may be interpreted as the zero order term of an expansion in   cavity connected correlations  \\nMISC\\tthese quantities are parameterizations of the   cavity distributions     i e   the  distribution over neighbor variables of a central variable which has been removed from the graph\\nMISC\\tthe bethe approximation and bp are recovered when this  cavity distribution is assumed to factorize  whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION\\nMISC\\testimation of these pair cumulants is possible with extra runs of bp  allowing for new polynomial time algorithms  reducing errors to order    when applying algorithms of which running time scales with an extra factor  of    CITATION\\nMISC\\talthough this scaling seems heavy  the large benefit of the approach is that it does not require selection of basic clusters or underlying  tree structures  since it takes into account the effect of all loops that contribute to nontrivial correlations in the cavity distribution at once\\nMISC\\tthe above   loop correction    strategy is applicable in the class of models where a perturbative expansion around the bethe approximation makes sense  i e   in models with large loops and relatively weak interactions\\nMISC\\tthe principal requirement  is that the magnitude of pair variable cumulants of cavity distributions is an order smaller than the  single variable cumulants  and third order cumulants are even smaller  etc\\nMISC\\thowever  heuristics based on the strategy allow for other good algorithms  performing well outside these parameter regimes  CITATION\\nCONT\\tso far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION\\nAIMX\\tin this paper we apply the idea to graphical models for continuous variables\\nOWNX\\twe derive the loop corrected belief propagation equations  for simple tractable gaussian models   yielding a message passing scheme that  besides the correct average marginals  also yields the correct variances\\nOWNX\\tbesides that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary   and the relation with expectation propagation\\nCONT\\ta by product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for gaussian models like the one discussed in  CITATION   but without explicitly using linear response\\n\\n\\nAIMX In this paper we derive the equations for Loop Corrected Belief Propagation on a continuous variable Gaussian model\\nOWNX Using the exactness of the averages for belief propagation for Gaussian models, a  different way of obtaining the covariances is found,  based on Belief Propagation on cavity graphs\\nAIMX We discuss the relation of this  loop correction algorithm to Expectation Propagation  algorithms for the case in which the model is no longer  Gaussian, but slightly perturbed by nonlinear terms\\n\\n\\nMISC Message passing techniques in graphical models allow for the computation of (approximate)  marginal probabilities in a time interval scaling polynomially in the  model size\\nMISC Their discovery has consequently revolutionized several  fields of applications in the past years, of which error correcting codes and vision are probably the most prominent examples\\nMISC In many cases, the corresponding graphs are loopy, implying either that the error resulting from the application of loopy belief propagation (BP) is negligible for the particular model, or it  can be tolerated for the particular purpose BP serves\\nMISC In other cases  more sophisticated refinements of BP are necessary, taking into account (part of) the loop errors\\nMISC Finding the optimal treatment of these ``loop errors\\'\\'  motivates an active field of research, in which  different solutions applying to different model classes are developed\\nMISC For models involving many short loops,  like on regular lattices, CVM type approaches work well  CITATION , or tree EP approaches  CITATION\\nMISC The latter may also be  applied to correct for an incidental large loop\\nMISC Unifying frameworks like the Region graphs of  CITATION   lead to general strategies for selecting the basic clusters underlying such approaches for general model classes\\nMISC A recent analysis has shown that the local update equations of BP may be interpreted as the zero order term of an expansion in ``cavity connected correlations\\'\\'\\nMISC These quantities are parameterizations of the ``cavity distributions\\'\\',  i e , the  distribution over neighbor variables of a central variable which has been removed from the graph\\nMISC The Bethe approximation and BP are recovered when this  cavity distribution is assumed to factorize, whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION\\nMISC Estimation of these pair cumulants is possible with extra runs of BP, allowing for new polynomial time algorithms, reducing errors to order  SYMBOL   when applying algorithms of which running time scales with an extra factor  of  SYMBOL   CITATION\\nMISC Although this scaling seems heavy, the large benefit of the approach is that it does not require selection of basic clusters or underlying  tree-structures, since it takes into account the effect of all loops that contribute to nontrivial correlations in the cavity distribution at once\\nMISC The above ``loop correction\\'\\'  strategy is applicable in the class of models where a perturbative expansion around the Bethe approximation makes sense, i e , in models with large loops and relatively weak interactions\\nMISC The principal requirement  is that the magnitude of pair variable cumulants of cavity distributions is an order smaller than the  single variable cumulants, and third order cumulants are even smaller, etc\\nMISC However, heuristics based on the strategy allow for other good algorithms  performing well outside these parameter regimes  CITATION\\nMISC So far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION\\nAIMX In this paper we apply the idea to graphical models for continuous variables\\nOWNX We derive the loop corrected belief propagation equations  for simple tractable Gaussian models,  yielding a message passing scheme that, besides the correct average marginals, also yields the correct variances\\nAIMX Besides that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary,  and the relation with expectation propagation\\nOWNX A by-product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for Gaussian models like the one discussed in  CITATION , but without explicitly using linear response\\n\\nMISC Defensive forecasting is a method of transforming laws of probability (stated in game-theoretic terms as strategies for Sceptic) into forecasting algorithms\\nMISC There are two known varieties of defensive forecasting: ``continuous\\'\\', in which Sceptic\\'s moves are assumed to depend on the forecasts in a (semi)continuous manner and which produces deterministic forecasts, and ``randomized\\'\\', in which the dependence of Sceptic\\'s moves on the forecasts is arbitrary and Forecaster\\'s moves are allowed to be randomized\\nAIMX This note shows that the randomized variety can be obtained from the continuous variety by smearing Sceptic\\'s moves to make them continuous\\nOWNX New as compared to version 1 (17 August 2007) of this report: The assumption of version 1 that the outcome space  SYMBOL  is finite is relaxed, and now it is only assumed to be compact\\nOWNX In the case where  SYMBOL  is finite, it is shown that Forecaster can choose his randomized forecasts concentrated on a finite set of cardinality at most  SYMBOL\\n\\n\\nMISC The continuous variety of defensive forecasting was essentially introduced by Levin  CITATION , but was later rediscovered by Kakade and Foster  CITATION  and Takemura  et al CITATION\\nMISC The randomized variety was introduced (in the case of von Mises\\'s version of the game-theoretic approach to probability) by Foster and Vohra  CITATION  and further developed by, among others, Sandroni  et al CITATION ; these papers, however, were only concerned with asymptotic calibration\\nMISC Non-asymptotic versions of the randomized variety were proposed by Sandroni  CITATION  (based on standard measure-theoretic probability) and Vovk and Shafer  CITATION  (based on game-theoretic probability)\\nBASE Kakade and Foster  CITATION  noticed that some calibration results require very little randomization (this will be an important aspect of our Theorem )\\nAIMX This note states two simple results about defensive forecasting, Theorem  about the continuous variety and Theorem  about the randomized variety\\nOWNX The proof of Theorem  is obtained from the proof of Theorem  by blurring Sceptic\\'s moves\\nOWNX In our informal discussions we will be assuming that the set  SYMBOL  of all possible outcomes is finite, although we will try to make mathematical statements as general as possible\\nMISC The reader who is only interested in the main ideas might choose to specialize Theorems  and  and their proofs to the case of finite  SYMBOL\\n\\n\\nCONT\\tmost generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used  independently of any algorithm\\nCONT\\tin contrast  the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties\\nCONT\\thowever  as in much of learning theory  existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed\\nCONT\\tin many machine learning applications  however  this assumption does not hold\\nCONT\\tthe observations received by the learning algorithm often have some inherent temporal dependence\\nAIMX\\tthis paper studies the scenario where the observations are drawn from a stationary   mixing or   mixing sequence  a widely adopted assumption in the study of non independent and identically distributed   processes that implies a dependence between observations weakening over time\\nOWNX\\twe prove novel and distinct stability based generalization bounds for stationary   mixing and   mixing sequences\\nBASE\\tthese bounds strictly generalize the bounds given in the independent and identically distributed   case and apply to all stable learning algorithms  thereby extending the use of stability bounds to non independent and identically distributed   scenarios\\nOWNX\\twe also illustrate the application of our   mixing generalization bounds to general classes of learning algorithms  including support vector regression  kernel ridge regression  and support vector machines  and many other kernel regularization based and relative entropy based regularization algorithms\\nOWNX\\tthese novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non independent and identically distributed   scenarios   \\n\\n\\nCONT\\tmost generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used  such as the vc dimension  covering numbers  or rademacher complexity\\nCONT\\tthese measures characterize a class of hypotheses  independently of any algorithm\\nCONT\\tin contrast  the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties\\nCONT\\ta learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set\\nCONT\\talgorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION\\nCONT\\tbut  as in much of learning theory  existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed  independent and identically distributed  \\nCONT\\tin many machine learning applications  this assumption  however  does not hold  in fact  the independent and identically distributed   assumption is not tested or derived from any data analysis\\nCONT\\tthe observations received by the learning algorithm often have some inherent temporal dependence\\nCONT\\tthis is clear in system diagnosis or time series prediction problems\\nCONT\\tclearly  prices of different stocks on the same day  or of the same stock on different days  may be dependent\\nCONT\\tbut  a less apparent time dependency may affect data sampled in many other tasks as well\\nAIMX\\tthis paper studies the scenario where the observations are drawn from a stationary   mixing or   mixing sequence  a widely adopted assumption in the study of non independent and identically distributed   processes that implies a dependence between observations weakening over time  CITATION\\nOWNX\\twe prove novel and distinct stability based generalization bounds for stationary   mixing and   mixing sequences\\nBASE\\tthese bounds strictly generalize the bounds given in the independent and identically distributed   case and apply to all stable learning algorithms  thereby extending the usefulness of stability bounds to non independent and identically distributed   scenarios\\nBASE\\tour proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION   which is commonly used in such contexts\\nCONT\\thowever  our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size\\nBASE\\tfor our analysis of stationary   mixing sequences  we make use of a generalized version of mcdiarmid s inequality  CITATION  that holds for   mixing sequences\\nBASE\\tthis leads to stability based generalization bounds with the standard exponential form\\nOWNX\\tour generalization bounds for stationary   mixing sequences cover a more general non independent and identically distributed   scenario and use the standard mcdiarmid s inequality  however  unlike the   mixing case  the   mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient\\nOWNX\\twe also illustrate the application of our   mixing generalization bounds to general classes of learning algorithms  including support vector regression  svr   CITATION   kernel ridge regression  CITATION   and support vector machines  svms   CITATION\\nCONT\\talgorithms such as support vector regression  svr   CITATION  have been used in the context of time series prediction in which the independent and identically distributed   assumption does not hold  some with good experimental results  CITATION\\nCONT\\tto our knowledge  the use of these algorithms in non independent and identically distributed   scenarios has not been previously supported by any theoretical analysis\\nCONT\\tthe stability bounds we give for svr  svms  and many other kernel regularization based and relative entropy based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios\\nOWNX\\tthe following sections are organized as follows\\nOWNX\\tin section   we introduce the necessary definitions for the non independent and identically distributed   problems that we are considering and discuss the learning scenarios in that context\\nOWNX\\tsection  gives our main generalization bounds for stationary   mixing sequences based on stability  as well as the illustration of its applications to general kernel regularization based algorithms  including svr  krr  and svms  as well as to relative entropy based regularization algorithms\\nOWNX\\tfinally  section  presents the first known stability bounds for the more general stationary   mixing scenario\\n\\n\\nMISC Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm\\nMISC In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties\\nMISC However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed\\nMISC In many machine learning applications, however, this assumption does not hold\\nMISC The observations received by the learning algorithm often have some inherent temporal dependence\\nAIMX This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid  processes that implies a dependence between observations weakening over time\\nAIMX We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences\\nOWNX These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-iid scenarios\\nOWNX We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms\\nOWNX These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-iid scenarios\\n\\n\\nMISC Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, such as the VC-dimension, covering numbers, or Rademacher complexity\\nMISC These measures characterize a class of hypotheses, independently of any algorithm\\nMISC In contrast, the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties\\nMISC A learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set\\nMISC Algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION\\nMISC But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (iid)\\nMISC In many machine learning applications, this assumption, however, does not hold; in fact, the iid assumption is not tested or derived from any data analysis\\nMISC The observations received by the learning algorithm often have some inherent temporal dependence\\nMISC This is clear in system diagnosis or time series prediction problems\\nMISC Clearly, prices of different stocks on the same day, or of the same stock on different days, may be dependent\\nMISC But, a less apparent time dependency may affect data sampled in many other tasks as well\\nAIMX This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid processes that implies a dependence between observations weakening over time  CITATION\\nAIMX We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences\\nOWNX These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the usefulness of stability-bounds to non-iid scenarios\\nBASE Our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION , which is commonly used in such contexts\\nCONT However, our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size\\nBASE For our analysis of stationary  SYMBOL -mixing sequences, we make use of a generalized version of McDiarmid\\'s inequality  CITATION  that holds for  SYMBOL -mixing sequences\\nBASE This leads to stability-based generalization bounds with the standard exponential form\\nCONT Our generalization bounds for stationary  SYMBOL -mixing sequences cover a more general non-iid scenario and use the standard McDiarmid\\'s inequality, however, unlike the  SYMBOL -mixing case, the  SYMBOL -mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient\\nOWNX We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression (SVR)  CITATION , Kernel Ridge Regression  CITATION , and Support Vector Machines (SVMs)  CITATION\\nOWNX Algorithms such as support vector regression (SVR)  CITATION  have been used in the context of time series prediction in which the iid assumption does not hold, some with good experimental results  CITATION\\nCONT To our knowledge, the use of these algorithms in non-iid scenarios has not been previously supported by any theoretical analysis\\nOWNX The stability bounds we give for SVR, SVMs, and many other kernel regularization-based and relative entropy-based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios\\nOWNX The following sections are organized as follows\\nOWNX In Section~, we introduce the necessary definitions for the non-iid problems that we are considering and discuss the learning scenarios in that context\\nOWNX Section~ gives our main generalization bounds for stationary  SYMBOL -mixing sequences based on stability, as well as the illustration of its applications to general kernel regularization-based algorithms, including SVR, KRR, and SVMs, as well as to relative entropy-based regularization algorithms\\nOWNX Finally, Section~ presents the first known stability bounds for the more general stationary  SYMBOL -mixing scenario \\n\\nMISC Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm\\nMISC In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties\\nMISC However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed\\nMISC In many machine learning applications, however, this assumption does not hold\\nMISC The observations received by the learning algorithm often have some inherent temporal dependence\\nAIMX This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid  processes that implies a dependence between observations weakening over time\\nOWNX We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences\\nOWNX These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-iid scenarios\\nOWNX We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms\\nOWNX These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-iid scenarios\\n\\n\\nMISC Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, such as the VC-dimension, covering numbers, or Rademacher complexity\\nMISC These measures characterize a class of hypotheses, independently of any algorithm\\nMISC In contrast, the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties\\nMISC A learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set\\nMISC Algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION\\nMISC But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (iid)\\nMISC In many machine learning applications, this assumption, however, does not hold; in fact, the iid assumption is not tested or derived from any data analysis\\nMISC The observations received by the learning algorithm often have some inherent temporal dependence\\nMISC This is clear in system diagnosis or time series prediction problems\\nMISC Clearly, prices of different stocks on the same day, or of the same stock on different days, may be dependent\\nMISC But, a less apparent time dependency may affect data sampled in many other tasks as well\\nAIMX This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid processes that implies a dependence between observations weakening over time  CITATION\\nOWNX We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences\\nOWNX These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the usefulness of stability-bounds to non-iid scenarios\\nBASE Our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION , which is commonly used in such contextsMISC\\nCONT However, our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size\\nBASE For our analysis of stationary  SYMBOL -mixing sequences, we make use of a generalized version of McDiarmid\\'s inequality  CITATION  that holds for  SYMBOL -mixing sequences\\nOWNX This leads to stability-based generalization bounds with the standard exponential form\\nOWNX Our generalization bounds for stationary  SYMBOL -mixing sequences cover a more general non-iid scenario and use the standard McDiarmid\\'s inequality, however, unlike the  SYMBOL -mixing case, the  SYMBOL -mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient\\nOWNX We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression (SVR)  CITATION , Kernel Ridge Regression  CITATION , and Support Vector Machines (SVMs)  CITATION\\nMISC Algorithms such as support vector regression (SVR)  CITATION  have been used in the context of time series prediction in which the iid assumption does not hold, some with good experimental results  CITATION\\nMISC To our knowledge, the use of these algorithms in non-iid scenarios has not been previously supported by any theoretical analysis\\nOWNX The stability bounds we give for SVR, SVMs, and many other kernel regularization-based and relative entropy-based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios\\nMISC The following sections are organized as follows\\nOWNX In Section~, we introduce the necessary definitions for the non-iid problems that we are considering and discuss the learning scenarios in that context\\nOWNX Section~ gives our main generalization bounds for stationary  SYMBOL -mixing sequences based on stability, as well as the illustration of its applications to general kernel regularization-based algorithms, including SVR, KRR, and SVMs, as well as to relative entropy-based regularization algorithms\\nOWNX Finally, Section~ presents the first known stability bounds for the more general stationary  SYMBOL -mixing scenario\\n\\n\\nAIMX\\tthis paper studies quantum annealing  qa  for clustering  which can be seen as an extension of simulated annealing  sa \\nOWNX\\twe derive a qa algorithm for clustering and propose an annealing schedule  which is crucial in practice\\nCONT\\texperiments show the proposed qa algorithm finds better clustering assignments than sa\\nCONT\\tfurthermore  qa is as easy as sa to implement\\n\\n\\nMISC\\tclustering is one of the most popular methods in data mining\\nMISC\\ttypically  clustering problems are formulated as optimization problems  which are solved by algorithms  for example the em algorithm or convex relaxation\\nMISC\\thowever  clustering is typically np hard\\nMISC\\tthe simulated annealing  sa   CITATION  is a promising candidate\\nMISC\\tCITATION  proved sa was able to find the global optimum with a slow cooling schedule of temperature\\nCONT\\talthough their schedule is in practice too slow for clustering of a large amount of data  it is well known that sa still finds a reasonably good solution even with a faster schedule than what  citeauthor geman NUMBER   proposed\\nCONT\\tin statistical mechanics  quantum annealing  qa  has been proposed as a novel alternative to sa  CITATION\\nCONT\\tqa adds another dimension     to sa for annealing  see fig\\nBASE\\tthus  it can be seen as an extension of sa\\nMISC\\tqa has succeeded in specific problems  e g the ising model in statistical mechanics  and it is still unclear that qa works better than sa in general\\nOWNX\\twe do not actually think qa intuitively helps clustering  but we apply qa to clustering just as procedure to derive an algorithm\\nMISC\\ta derived qa algorithm depends on the definition of quantum effect\\nOWNX\\twe propose quantum effect    which leads to a search strategy fit to clustering\\nAIMX\\tour contribution is 1) to propose a qa based optimization algorithm for clustering in particular quantum effect for clustering and a good annealing schedule  which is crucial for applications 2) and to experimentally show the proposed algorithm optimizes clustering assignments better than sa\\nOWNX\\twe also show the proposed algorithm is as easy as sa to implement \\nOWNX \\tthe algorithm we propose is a markov chain monte carlo  mcmc  sampler  which we call qa st sampler\\nOWNX\\tas we explain later  a naive qa sampler is intractable even with mcmc\\nOWNX\\tthus  we approximate qa by the suzuki trotter  st  expansion  CITATION  to derive a tractable sampler  which is the qa st sampler\\nOWNX\\tqa st looks like parallel   sas with interaction    see fig  \\nOWNX\\tat the beginning of the annealing process  qa st is almost the same as   sas\\nOWNX\\thence  qa st finds    local  optima independently\\nOWNX\\tas the annealing process continues  interaction   in fig becomes stronger to move   states closer\\nOWNX\\tqa st at the end picks up the state with the lowest energy in   states as the final solution\\nOWNX\\tqa st with the proposed quantum effect   works well for clustering\\nOWNX\\tfig is an example where data points are grouped into four clusters\\nOWNX\\tSYMBOL and SYMBOL are locally optimal and   is globally optimal\\nOWNX\\tsuppose SYMBOL is equal to two and SYMBOL and SYMBOL in fig correspond to SYMBOL and SYMBOL in fig\\nOWNX\\talthough   and   are local optima  the interaction   in fig allows   and   to search for a better clustering assignment between   and\\nOWNX\\tquantum effect   defines the distance metric of clustering assignments\\nOWNX\\tin this case  the proposed   locates   between   and\\nOWNX\\tthus  the interaction   gives good chance to go to   because   makes   and   closer  see fig  \\nOWNX\\tthe proposed algorithm actually finds   from   and\\nOWNX\\tfig is just an example\\nMISC\\thowever  a similar situation often occurs in clustering\\nMISC\\tclustering algorithms in most cases give   almost   globally optimal solutions like   and    where the majority of data points are well clustered  but some of them are not\\nMISC\\tthus  a better clustering assignment can be constructed by picking up well clustered data points from many sub optimal clustering assignments\\nMISC\\tnote an assignment constructed in such a way is located between the sub optimal ones by the proposed quantum effect   so that qa st can find a better assignment between sub optimal ones\\n'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [i for i in glob.glob(os.path.expanduser(\"./labeled_dataset/*.txt\"))]\n",
    "\n",
    "# Initialize an empty string\n",
    "rawLabeledData = \"\"\n",
    "\n",
    "# Loop through the files and read each into the string\n",
    "for file in filenames:\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "        # Remove unecessary titles\n",
    "        content = content.replace('### abstract ###', '\\n').replace('### introduction ###', '\\n')\n",
    "    rawLabeledData += content\n",
    "\n",
    "rawLabeledData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13182d33-4b17-4d9e-b131-d0f31b355a30",
   "metadata": {},
   "source": [
    "### B) Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ae4c6-5f86-4489-9859-c8620d7b156a",
   "metadata": {},
   "source": [
    "#### 1) Labelled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1812345-bc97-463d-b409-49073a55dc3a",
   "metadata": {},
   "source": [
    "#### Separate the label from the rest of the text for the labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1941fa39-32e1-4ecf-a1f9-9f3da9ebdd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2)\n",
      "   label                                                      content\n",
      "0   MISC  although the internet as level topology has been extensi...\n",
      "1   MISC  an as  node  can represent a wide variety of organizatio...\n",
      "2   AIMX  in this paper  we introduce a radically new approach bas...\n",
      "3   OWNX  we successfully classify  NUMBER   NUMBER  percent  of a...\n",
      "4   OWNX  we release to the community the as level topology datase...\n",
      "5   OWNX  we believe that this dataset will serve as an invaluable...\n",
      "6   MISC  the rapid expansion of the internet in the last two deca...\n",
      "7   MISC  from  NUMBER  to  NUMBER  the number of globally routabl...\n",
      "8   MISC  this impressive growth has resulted in a heterogenous an...\n",
      "9   MISC  in particular  the as level topology is an intermix of n...\n",
      "10  MISC  statistical information that faithfully characterizes di...\n",
      "11  MISC  in topology modeling  knowledge of as types is mandatory...\n",
      "12  MISC  for example  we expect the network of a dual homed unive...\n",
      "13  MISC  the university will likely contain dozens of internal ro...\n",
      "14  MISC  on the other hand  the small company will most probably ...\n",
      "15  MISC  since there is such a diversity among different network ...\n",
      "16  MISC  moreover  annotating the ases in the as topology with th...\n",
      "17  MISC  for example  internet service providers  isp  grow by at...\n",
      "18  MISC  on the other hand  small companies that connect to the i...\n",
      "19  MISC  thus  categorizing different types of ases in the intern...\n"
     ]
    }
   ],
   "source": [
    "# Split the raw data into lines\n",
    "lines = rawLabeledData.split('\\n')\n",
    "\n",
    "# Initialize lists to store labels and contents\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Loop through each line\n",
    "for line in lines:\n",
    "    if line:  # if line is not empty\n",
    "        # Check if the line has a tab character\n",
    "        if '\\t' in line:\n",
    "            # Split the line into label and content\n",
    "            split_line = re.split(r'\\t+', line)\n",
    "            # Remove trailing spaces from the label\n",
    "            label = split_line[0].strip()\n",
    "            labels.append(label)\n",
    "            contents.append(split_line[1])\n",
    "        else:\n",
    "            # Handle lines where label and content are separated by a single space\n",
    "            split_line = line.split(' ', 1)  # Split at the first space\n",
    "            if len(split_line) == 2:  # Ensure there are two parts\n",
    "                label, content = split_line\n",
    "                labels.append(label)\n",
    "                contents.append(content)\n",
    "            \n",
    "\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "\n",
    "# Create a DataFrame\n",
    "labeled_df = pd.DataFrame({\n",
    "    'label': labels,\n",
    "    'content': contents\n",
    "})\n",
    "\n",
    "print(labeled_df.shape)\n",
    "print(labeled_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2bc46a49-4193-4330-beec-1c21efdd7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MISC' 'AIMX' 'OWNX' 'BASE' 'CONT']\n"
     ]
    }
   ],
   "source": [
    "# Verify the unique labels\n",
    "print(labeled_df.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f81b7-f239-48c9-b923-603707fb4dfd",
   "metadata": {},
   "source": [
    "#### 2) Unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "fa6a1491-5691-41b0-846b-44080af529fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 1)\n",
      "                                                                                                content\n",
      "0   Whole-genome transporter analyses have been conducted on 141 organisms whose complete genome seq...\n",
      "1   For each organism, the complete set of membrane transport systems was identified with predicted ...\n",
      "2   Organisms with larger genome sizes generally possessed a relatively greater number of transport ...\n",
      "3   In prokaryotes and unicellular eukaryotes, the significant factor in the increase in transporter...\n",
      "4   In contrast, in multicellular eukaryotes, greater number of paralogs in specific transporter fam...\n",
      "5   Both eukaryotic and prokaryotic intracellular pathogens and endosymbionts exhibited markedly lim...\n",
      "6   Hierarchical clustering of phylogenetic profiles of transporter families, derived from the prese...\n",
      "7                Membrane transport systems play essential roles in cellular metabolism and activities.\n",
      "8   Transporters function in the acquisition of organic nutrients, maintenance of ion homeostasis, e...\n",
      "9   Various transport systems differ in their putative membrane topology, energy coupling mechanisms...\n",
      "10  Among the prevailing energy sources are adenosine triphosphate, phosphoenolpyruvate, and chemios...\n",
      "11  The transporter classification system represents a systematic approach to classify transport sys...\n",
      "12  Transport mode and energy coupling mechanism serve as the primary basis for classification becau...\n",
      "13  There are four major classes of solute transporters in the transporter classification system: ch...\n",
      "14                      Transporters of unknown mechanism or function are included as a distinct class.\n"
     ]
    }
   ],
   "source": [
    "# Split the raw data into lines\n",
    "lines = rawUnlabeledData.split('\\n')\n",
    "\n",
    "# Filter out empty lines\n",
    "lines = [line for line in lines if line.strip()]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Create a DataFrame\n",
    "unlabeled_df = pd.DataFrame(lines, columns=['content'])\n",
    "\n",
    "print(unlabeled_df.shape)\n",
    "print(unlabeled_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa52e91-5718-4621-b079-171febdc3c5f",
   "metadata": {},
   "source": [
    "#### Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7dbe9b02-d58a-40a3-9aa0-fe1d2b4c5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca64e4-958c-4a89-a26b-1b54fc866744",
   "metadata": {},
   "source": [
    "#### 1) Labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "811ec70d-2b83-47f3-ba03-29c21f8ca80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>although the internet as level topology has been extensively studied over the past few years  li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>an as  node  can represent a wide variety of organizations  e g   large isp  or small private bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIMX</td>\n",
       "      <td>in this paper  we introduce a radically new approach based on machine learning techniques to map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>we release to the community the as level topology dataset augmented with   NUMBER   the as taxon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0  MISC   \n",
       "1  MISC   \n",
       "2  AIMX   \n",
       "3  OWNX   \n",
       "4  OWNX   \n",
       "\n",
       "                                                                                               content  \n",
       "0  although the internet as level topology has been extensively studied over the past few years  li...  \n",
       "1  an as  node  can represent a wide variety of organizations  e g   large isp  or small private bu...  \n",
       "2  in this paper  we introduce a radically new approach based on machine learning techniques to map...  \n",
       "3  we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   ...  \n",
       "4  we release to the community the as level topology dataset augmented with   NUMBER   the as taxon...  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['content'] = labeled_df['content'].apply(lambda x: remove_punct(x))\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05fe767-58c3-4762-8316-29483980e35a",
   "metadata": {},
   "source": [
    "#### 2) Unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "04c0472c-27ac-4078-8c66-9c04f7e8f743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For each organism the complete set of membrane transport systems was identified with predicted functions and classified into p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organisms with larger genome sizes generally possessed a relatively greater number of transport systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important fac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             content\n",
       "0                Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available\n",
       "1  For each organism the complete set of membrane transport systems was identified with predicted functions and classified into p...\n",
       "2                            Organisms with larger genome sizes generally possessed a relatively greater number of transport systems\n",
       "3  In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a...\n",
       "4  In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important fac..."
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 130)\n",
    "unlabeled_df['content'] = unlabeled_df['content'].apply(lambda x: remove_punct(x))\n",
    "unlabeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78280106-ec35-40a8-9fc5-540bf619bff1",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1af052ee-c1e6-47a2-87b4-750b70a37f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each word\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b3a16-0ff7-46a5-9363-9459b006a423",
   "metadata": {},
   "source": [
    "#### 1) Labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "0f676247-85d6-4f36-a069-d8db4b1de08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>tk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>although the internet as level topology has been extensively studied over the past few years  little is known about the detail...</td>\n",
       "      <td>[although, the, internet, as, level, topology, has, been, extensively, studied, over, the, past, few, years, little, is, known...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>an as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastl...</td>\n",
       "      <td>[an, as, node, can, represent, a, wide, variety, of, organizations, e, g, large, isp, or, small, private, business, university...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIMX</td>\n",
       "      <td>in this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet ...</td>\n",
       "      <td>[in, this, paper, we, introduce, a, radically, new, approach, based, on, machine, learning, techniques, to, map, all, the, ase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent</td>\n",
       "      <td>[we, successfully, classify, number, number, percent, of, ases, with, expected, accuracy, of, number, number, percent, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>we release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   ...</td>\n",
       "      <td>[we, release, to, the, community, the, as, level, topology, dataset, augmented, with, number, the, as, taxonomy, information, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0  MISC   \n",
       "1  MISC   \n",
       "2  AIMX   \n",
       "3  OWNX   \n",
       "4  OWNX   \n",
       "\n",
       "                                                                                                                             content  \\\n",
       "0  although the internet as level topology has been extensively studied over the past few years  little is known about the detail...   \n",
       "1  an as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastl...   \n",
       "2  in this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet ...   \n",
       "3                   we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent    \n",
       "4  we release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   ...   \n",
       "\n",
       "                                                                                                                          tk_content  \n",
       "0  [although, the, internet, as, level, topology, has, been, extensively, studied, over, the, past, few, years, little, is, known...  \n",
       "1  [an, as, node, can, represent, a, wide, variety, of, organizations, e, g, large, isp, or, small, private, business, university...  \n",
       "2  [in, this, paper, we, introduce, a, radically, new, approach, based, on, machine, learning, techniques, to, map, all, the, ase...  \n",
       "3           [we, successfully, classify, number, number, percent, of, ases, with, expected, accuracy, of, number, number, percent, ]  \n",
       "4  [we, release, to, the, community, the, as, level, topology, dataset, augmented, with, number, the, as, taxonomy, information, ...  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['tk_content'] = labeled_df['content'].apply(lambda x: tokenize(x.lower()))\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123cef3f-210c-4b59-8ddc-92892d63dd28",
   "metadata": {},
   "source": [
    "#### 2) Unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5025aed0-4c7f-4389-a9c3-d0dfa3a4eb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available</td>\n",
       "      <td>[wholegenome, transporter, analyses, have, been, conducted, on, 141, organisms, whose, complete, genome, sequences, are, avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For each organism the complete set of membrane transport systems was identified with predicted functions and classified into p...</td>\n",
       "      <td>[for, each, organism, the, complete, set, of, membrane, transport, systems, was, identified, with, predicted, functions, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organisms with larger genome sizes generally possessed a relatively greater number of transport systems</td>\n",
       "      <td>[organisms, with, larger, genome, sizes, generally, possessed, a, relatively, greater, number, of, transport, systems]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a...</td>\n",
       "      <td>[in, prokaryotes, and, unicellular, eukaryotes, the, significant, factor, in, the, increase, in, transporter, content, with, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important fac...</td>\n",
       "      <td>[in, contrast, in, multicellular, eukaryotes, greater, number, of, paralogs, in, specific, transporter, families, was, the, mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             content  \\\n",
       "0                Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available   \n",
       "1  For each organism the complete set of membrane transport systems was identified with predicted functions and classified into p...   \n",
       "2                            Organisms with larger genome sizes generally possessed a relatively greater number of transport systems   \n",
       "3  In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a...   \n",
       "4  In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important fac...   \n",
       "\n",
       "                                                                                                                          tk_content  \n",
       "0  [wholegenome, transporter, analyses, have, been, conducted, on, 141, organisms, whose, complete, genome, sequences, are, avail...  \n",
       "1  [for, each, organism, the, complete, set, of, membrane, transport, systems, was, identified, with, predicted, functions, and, ...  \n",
       "2             [organisms, with, larger, genome, sizes, generally, possessed, a, relatively, greater, number, of, transport, systems]  \n",
       "3  [in, prokaryotes, and, unicellular, eukaryotes, the, significant, factor, in, the, increase, in, transporter, content, with, g...  \n",
       "4  [in, contrast, in, multicellular, eukaryotes, greater, number, of, paralogs, in, specific, transporter, families, was, the, mo...  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df['tk_content'] = unlabeled_df['content'].apply(lambda x: tokenize(x.lower()))\n",
    "unlabeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab843a-592a-4101-8bbb-558b74ae7c90",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2b6aa414-7680-4a5d-94e4-b5dab6adf011",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Only return the words that are not stopwords\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be135b0-89d8-4b96-b4c6-5b806d024976",
   "metadata": {},
   "source": [
    "#### 1) Labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "3c714aa6-78be-4bf1-979d-0167b47e76a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>tk_content</th>\n",
       "      <th>content_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>although the internet as level topology has been extensively studied over the past few years  little is known about the detail...</td>\n",
       "      <td>[although, the, internet, as, level, topology, has, been, extensively, studied, over, the, past, few, years, little, is, known...</td>\n",
       "      <td>[although, internet, level, topology, extensively, studied, past, years, little, known, details, taxonomy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>an as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastl...</td>\n",
       "      <td>[an, as, node, can, represent, a, wide, variety, of, organizations, e, g, large, isp, or, small, private, business, university...</td>\n",
       "      <td>[node, represent, wide, variety, organizations, e, g, large, isp, small, private, business, university, vastly, different, net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIMX</td>\n",
       "      <td>in this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet ...</td>\n",
       "      <td>[in, this, paper, we, introduce, a, radically, new, approach, based, on, machine, learning, techniques, to, map, all, the, ase...</td>\n",
       "      <td>[paper, introduce, radically, new, approach, based, machine, learning, techniques, map, ases, internet, natural, taxonomy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent</td>\n",
       "      <td>[we, successfully, classify, number, number, percent, of, ases, with, expected, accuracy, of, number, number, percent, ]</td>\n",
       "      <td>[successfully, classify, number, number, percent, ases, expected, accuracy, number, number, percent, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>we release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   ...</td>\n",
       "      <td>[we, release, to, the, community, the, as, level, topology, dataset, augmented, with, number, the, as, taxonomy, information, ...</td>\n",
       "      <td>[release, community, level, topology, dataset, augmented, number, taxonomy, information, number, set, attributes, used, classi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0  MISC   \n",
       "1  MISC   \n",
       "2  AIMX   \n",
       "3  OWNX   \n",
       "4  OWNX   \n",
       "\n",
       "                                                                                                                             content  \\\n",
       "0  although the internet as level topology has been extensively studied over the past few years  little is known about the detail...   \n",
       "1  an as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastl...   \n",
       "2  in this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet ...   \n",
       "3                   we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent    \n",
       "4  we release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   ...   \n",
       "\n",
       "                                                                                                                          tk_content  \\\n",
       "0  [although, the, internet, as, level, topology, has, been, extensively, studied, over, the, past, few, years, little, is, known...   \n",
       "1  [an, as, node, can, represent, a, wide, variety, of, organizations, e, g, large, isp, or, small, private, business, university...   \n",
       "2  [in, this, paper, we, introduce, a, radically, new, approach, based, on, machine, learning, techniques, to, map, all, the, ase...   \n",
       "3           [we, successfully, classify, number, number, percent, of, ases, with, expected, accuracy, of, number, number, percent, ]   \n",
       "4  [we, release, to, the, community, the, as, level, topology, dataset, augmented, with, number, the, as, taxonomy, information, ...   \n",
       "\n",
       "                                                                                                                      content_nostop  \n",
       "0                         [although, internet, level, topology, extensively, studied, past, years, little, known, details, taxonomy]  \n",
       "1  [node, represent, wide, variety, organizations, e, g, large, isp, small, private, business, university, vastly, different, net...  \n",
       "2         [paper, introduce, radically, new, approach, based, machine, learning, techniques, map, ases, internet, natural, taxonomy]  \n",
       "3                             [successfully, classify, number, number, percent, ases, expected, accuracy, number, number, percent, ]  \n",
       "4  [release, community, level, topology, dataset, augmented, number, taxonomy, information, number, set, attributes, used, classi...  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['content_nostop'] = labeled_df['tk_content'].apply(lambda x: remove_stopwords(x))\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f952a-e8c3-4cbb-8d79-da4391d60455",
   "metadata": {},
   "source": [
    "#### 2) Unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ec110118-0325-4f79-a2ed-a3d1854f4254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tk_content</th>\n",
       "      <th>content_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available</td>\n",
       "      <td>[wholegenome, transporter, analyses, have, been, conducted, on, 141, organisms, whose, complete, genome, sequences, are, avail...</td>\n",
       "      <td>[wholegenome, transporter, analyses, conducted, 141, organisms, whose, complete, genome, sequences, available]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For each organism the complete set of membrane transport systems was identified with predicted functions and classified into p...</td>\n",
       "      <td>[for, each, organism, the, complete, set, of, membrane, transport, systems, was, identified, with, predicted, functions, and, ...</td>\n",
       "      <td>[organism, complete, set, membrane, transport, systems, identified, predicted, functions, classified, protein, families, based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organisms with larger genome sizes generally possessed a relatively greater number of transport systems</td>\n",
       "      <td>[organisms, with, larger, genome, sizes, generally, possessed, a, relatively, greater, number, of, transport, systems]</td>\n",
       "      <td>[organisms, larger, genome, sizes, generally, possessed, relatively, greater, number, transport, systems]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a...</td>\n",
       "      <td>[in, prokaryotes, and, unicellular, eukaryotes, the, significant, factor, in, the, increase, in, transporter, content, with, g...</td>\n",
       "      <td>[prokaryotes, unicellular, eukaryotes, significant, factor, increase, transporter, content, genome, size, greater, diversity, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important fac...</td>\n",
       "      <td>[in, contrast, in, multicellular, eukaryotes, greater, number, of, paralogs, in, specific, transporter, families, was, the, mo...</td>\n",
       "      <td>[contrast, multicellular, eukaryotes, greater, number, paralogs, specific, transporter, families, important, factor, increase,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             content  \\\n",
       "0                Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available   \n",
       "1  For each organism the complete set of membrane transport systems was identified with predicted functions and classified into p...   \n",
       "2                            Organisms with larger genome sizes generally possessed a relatively greater number of transport systems   \n",
       "3  In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a...   \n",
       "4  In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important fac...   \n",
       "\n",
       "                                                                                                                          tk_content  \\\n",
       "0  [wholegenome, transporter, analyses, have, been, conducted, on, 141, organisms, whose, complete, genome, sequences, are, avail...   \n",
       "1  [for, each, organism, the, complete, set, of, membrane, transport, systems, was, identified, with, predicted, functions, and, ...   \n",
       "2             [organisms, with, larger, genome, sizes, generally, possessed, a, relatively, greater, number, of, transport, systems]   \n",
       "3  [in, prokaryotes, and, unicellular, eukaryotes, the, significant, factor, in, the, increase, in, transporter, content, with, g...   \n",
       "4  [in, contrast, in, multicellular, eukaryotes, greater, number, of, paralogs, in, specific, transporter, families, was, the, mo...   \n",
       "\n",
       "                                                                                                                      content_nostop  \n",
       "0                     [wholegenome, transporter, analyses, conducted, 141, organisms, whose, complete, genome, sequences, available]  \n",
       "1  [organism, complete, set, membrane, transport, systems, identified, predicted, functions, classified, protein, families, based...  \n",
       "2                          [organisms, larger, genome, sizes, generally, possessed, relatively, greater, number, transport, systems]  \n",
       "3  [prokaryotes, unicellular, eukaryotes, significant, factor, increase, transporter, content, genome, size, greater, diversity, ...  \n",
       "4  [contrast, multicellular, eukaryotes, greater, number, paralogs, specific, transporter, families, important, factor, increase,...  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df['content_nostop'] = unlabeled_df['tk_content'].apply(lambda x: remove_stopwords(x))\n",
    "unlabeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ec14f-2e71-4278-bc63-cea43e2a1a4a",
   "metadata": {},
   "source": [
    "#### Vectorize the sentences using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45241fd-a3e4-4e42-ae5c-c1e99511b928",
   "metadata": {},
   "source": [
    "#### Join the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "02284056-76ec-4310-a3e5-e756a5cecbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label          content       tk_content   content_nostop content_nostop_str\n",
      "0  MISC  although the...  [although, t...  [although, i...  although int...  \n",
      "1  MISC  an as  node ...  [an, as, nod...  [node, repre...  node represe...  \n",
      "2  AIMX  in this pape...  [in, this, p...  [paper, intr...  paper introd...  \n",
      "3  OWNX  we successfu...  [we, success...  [successfull...  successfully...  \n",
      "4  OWNX  we release t...  [we, release...  [release, co...  release comm...  \n",
      "           content       tk_content   content_nostop content_nostop_str\n",
      "0  Wholegenome ...  [wholegenome...  [wholegenome...  wholegenome ...  \n",
      "1  For each org...  [for, each, ...  [organism, c...  organism com...  \n",
      "2  Organisms wi...  [organisms, ...  [organisms, ...  organisms la...  \n",
      "3  In prokaryot...  [in, prokary...  [prokaryotes...  prokaryotes ...  \n",
      "4  In contrast ...  [in, contras...  [contrast, m...  contrast mul...  \n"
     ]
    }
   ],
   "source": [
    "# join the processed words in labelled and unlabelled dataset\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "labeled_df['content_nostop_str'] = labeled_df['content_nostop'].apply(' '.join)\n",
    "unlabeled_df['content_nostop_str'] = unlabeled_df['content_nostop'].apply(' '.join)\n",
    "print(labeled_df.head())\n",
    "print(unlabeled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "b4c5260f-53e2-4f37-8b2a-cecd563f9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 1333)\n",
      "(110, 1333)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the vectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "combined_data = pd.concat([labeled_df['content_nostop_str'], unlabeled_df['content_nostop_str']])\n",
    "\n",
    "tfidf_vect.fit(combined_data)\n",
    "\n",
    "# Transform the labelled and unlabelled data\n",
    "X_tfidf = tfidf_vect.transform(labeled_df['content_nostop_str'])\n",
    "X_unlabeled = tfidf_vect.transform(unlabeled_df['content_nostop_str'])\n",
    "\n",
    "print(X_tfidf.shape)\n",
    "print(X_unlabeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "44588df5-ce47-4b28-afbf-8c475b607590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>1100</th>\n",
       "      <th>141</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>1997</th>\n",
       "      <th>200</th>\n",
       "      <th>2000</th>\n",
       "      <th>20000</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>years</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yields</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows  1333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     11  1100  141   16   17   18  1997  200  2000  20000  ...      work  \\\n",
       "30  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.395244   \n",
       "31  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "32  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "33  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "34  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "35  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "36  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "37  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "38  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "39  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "40  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "41  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "42  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "43  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "44  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0    0.0  ...  0.000000   \n",
       "\n",
       "     working  works  world     years  yeast  yielded  yielding  yields  zero  \n",
       "30  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "31  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "32  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "33  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "34  0.000000    0.0    0.0  0.316396    0.0      0.0       0.0     0.0   0.0  \n",
       "35  0.195148    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "36  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "37  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "38  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "39  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "40  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "41  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "42  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "43  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "44  0.000000    0.0    0.0  0.000000    0.0      0.0       0.0     0.0   0.0  \n",
       "\n",
       "[15 rows x 1333 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a sample of the vectorized sentences\n",
    "\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_df.columns = tfidf_vect.get_feature_names_out()\n",
    "X_tfidf_df.iloc[30:45, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4ca00-bef7-4bce-ad74-dfaf145f05c5",
   "metadata": {},
   "source": [
    "### Create a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a61a2b41-fe97-4fc2-8889-a12591e67c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Set the label\n",
    "y = le.fit_transform(labeled_df['label'])\n",
    "# Set the feature (the vectorized sentences)\n",
    "X = X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "e075861e-11f0-4b93-9a3f-30644a02e57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c9ced-3ef9-4197-abf6-5213269c3b8c",
   "metadata": {},
   "source": [
    "### Prediction of the class from the unlabelled set with each sentence preceded by the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "20cec222-a0a0-470e-9f90-6e57cb2712ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_unlabeled = clf.predict(X_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "37e9f852-52ec-4bef-9ff3-22eabb539e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels back to their original form\n",
    "unlabeled_df['predicted_label'] = le.inverse_transform(y_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2cf9efb4-ca8d-4efc-b498-d8457c5b16a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>For each organism the complete set of membrane transport systems was identified with predicted functions and classified into protein families base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Organisms with larger genome sizes generally possessed a relatively greater number of transport systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a greater diversity o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISC</td>\n",
       "      <td>In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important factor in the increase ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>The synthetic datasets consist of mixtures of WM samples and random sequences which is in accordance with assumptions that all algorithms make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>MISC</td>\n",
       "      <td>This allows us to compare the performance of the algorithms in an idealized situation that does not contain the complexities of real data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>These tests also show to what extent binding sites can be recovered for this idealized data as a function of the quality of the WMs the number of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>For our tests on real data we use 200 upstream regions from Saccharomyces cerevisiae that have known binding sites from the collection CITATION an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>Finally we run PhyloGibbs on collections of upstream region alignments that were annotated in CITATION to contain binding sites for a common TF ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_label  \\\n",
       "0              OWNX   \n",
       "1              OWNX   \n",
       "2              MISC   \n",
       "3              MISC   \n",
       "4              MISC   \n",
       "..              ...   \n",
       "105            OWNX   \n",
       "106            MISC   \n",
       "107            OWNX   \n",
       "108            OWNX   \n",
       "109            OWNX   \n",
       "\n",
       "                                                                                                                                                   content  \n",
       "0                                      Wholegenome transporter analyses have been conducted on 141 organisms whose complete genome sequences are available  \n",
       "1    For each organism the complete set of membrane transport systems was identified with predicted functions and classified into protein families base...  \n",
       "2                                                  Organisms with larger genome sizes generally possessed a relatively greater number of transport systems  \n",
       "3    In prokaryotes and unicellular eukaryotes the significant factor in the increase in transporter content with genome size was a greater diversity o...  \n",
       "4    In contrast in multicellular eukaryotes greater number of paralogs in specific transporter families was the more important factor in the increase ...  \n",
       "..                                                                                                                                                     ...  \n",
       "105         The synthetic datasets consist of mixtures of WM samples and random sequences which is in accordance with assumptions that all algorithms make  \n",
       "106              This allows us to compare the performance of the algorithms in an idealized situation that does not contain the complexities of real data  \n",
       "107  These tests also show to what extent binding sites can be recovered for this idealized data as a function of the quality of the WMs the number of ...  \n",
       "108  For our tests on real data we use 200 upstream regions from Saccharomyces cerevisiae that have known binding sites from the collection CITATION an...  \n",
       "109  Finally we run PhyloGibbs on collections of upstream region alignments that were annotated in CITATION to contain binding sites for a common TF ba...  \n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the label predictions\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "unlabeled_df[['predicted_label', 'content']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81215e4-d1ac-480e-b4a2-b13752bd62c2",
   "metadata": {},
   "source": [
    "#### Accuracy of classifier, comparing predictions made for the training set to the actual training set labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ba6fdaf5-13e4-44ec-9b72-9ba1b98b701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier on the training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training set\n",
    "y_train_pred = clf.predict(X_tfidf)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "\n",
    "print(f'Accuracy of the classifier on the training set: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c783a006-2d05-4324-90cc-4e430fec897d",
   "metadata": {},
   "source": [
    "### Summary of the work and findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438dd30-81bf-4ff0-ae04-66131283f7dc",
   "metadata": {},
   "source": [
    "The raw text from the labelled and unlabelled documents were loaded and stored in pandas data frames. As part of the data preprocessing, stop words words and punctuations were removed from the data, and the sentences were tokenized. The preprocessed text was then converted into its numerical representation using the TF-IDF method, which resulted in a matrix where each row represents a document and each column represents a word.\n",
    "\n",
    "Moreover, a Multinomial Naive Bayes classifier was used to train on the labelled data. The trained classifier was used to predict the labels of the unlabelled data, which involved transforming the unlabelled data into the same TF-IDF format as the training data and passing it to the Naive Bayes classifier's predict() method.\n",
    "\n",
    "Finally, the Naive Bayes classifier's performance was evaluated by comparing its predictions on the training set to the actual labels. It returned an accuracy of 81%. In a normal model evaluation, an accuracy of 81% is a good result. However, high accuracy on the same training set could be a sign of overfitting or underfitting in this scenario. It is generally a better practice to evaluate a model on a separate test set, which can provide a more realistic estimate of how the model will perform on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
